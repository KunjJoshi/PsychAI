{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://huggingface.co/datasets/Garsa3112/TestingMain/resolve/main/MentalHealth.csv","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:14:06.514867Z","iopub.execute_input":"2024-01-31T17:14:06.515161Z","iopub.status.idle":"2024-01-31T17:14:07.783889Z","shell.execute_reply.started":"2024-01-31T17:14:06.515128Z","shell.execute_reply":"2024-01-31T17:14:07.782588Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2024-01-31 17:14:07--  https://huggingface.co/datasets/Garsa3112/TestingMain/resolve/main/MentalHealth.csv\nResolving huggingface.co (huggingface.co)... 3.163.189.37, 3.163.189.74, 3.163.189.114, ...\nConnecting to huggingface.co (huggingface.co)|3.163.189.37|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4637006 (4.4M) [text/plain]\nSaving to: 'MentalHealth.csv'\n\nMentalHealth.csv    100%[===================>]   4.42M  29.4MB/s    in 0.2s    \n\n2024-01-31 17:14:07 (29.4 MB/s) - 'MentalHealth.csv' saved [4637006/4637006]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#!pip install --upgrade safetensors peft transformers\n#!conda update --all --y","metadata":{"execution":{"iopub.status.busy":"2024-01-31T15:20:37.702635Z","iopub.execute_input":"2024-01-31T15:20:37.703050Z","iopub.status.idle":"2024-01-31T15:20:37.707488Z","shell.execute_reply.started":"2024-01-31T15:20:37.703017Z","shell.execute_reply":"2024-01-31T15:20:37.706722Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv('/kaggle/working/MentalHealth.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:14:07.786032Z","iopub.execute_input":"2024-01-31T17:14:07.786347Z","iopub.status.idle":"2024-01-31T17:14:08.994485Z","shell.execute_reply.started":"2024-01-31T17:14:07.786320Z","shell.execute_reply":"2024-01-31T17:14:08.993552Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install -U pip\n!pip install accelerate==0.18.0\n!pip install appdirs==1.4.4\n!pip install bitsandbytes>=0.37.2\n!pip install datasets==2.10.1\n!pip install fire==0.5.0\n!pip install git+https://github.com/huggingface/peft.git\n!pip install git+https://github.com/huggingface/transformers.git\n!pip install torch==2.0.0\n!pip install sentencepiece==0.1.97\n!pip install tensorboardX==2.6\n!pip install gradio==3.23.0","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:14:08.995759Z","iopub.execute_input":"2024-01-31T17:14:08.996098Z","iopub.status.idle":"2024-01-31T17:17:55.397134Z","shell.execute_reply.started":"2024-01-31T17:14:08.996064Z","shell.execute_reply":"2024-01-31T17:17:55.396128Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.2.1)\nCollecting pip\n  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/15/aa/3f4c7bcee2057a76562a5b33ecbd199be08cdb4443a02e26bd2c3cf6fc39/pip-23.3.2-py3-none-any.whl.metadata\n  Downloading pip-23.3.2-py3-none-any.whl.metadata (3.5 kB)\nDownloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.2.1\n    Uninstalling pip-23.2.1:\n      Successfully uninstalled pip-23.2.1\nSuccessfully installed pip-23.3.2\nCollecting accelerate==0.18.0\n  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.18.0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.18.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.18.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.18.0) (6.0.1)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.18.0) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.18.0) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->accelerate==0.18.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->accelerate==0.18.0) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.25.0\n    Uninstalling accelerate-0.25.0:\n      Successfully uninstalled accelerate-0.25.0\nSuccessfully installed accelerate-0.18.0\nRequirement already satisfied: appdirs==1.4.4 in /opt/conda/lib/python3.10/site-packages (1.4.4)\nCollecting datasets==2.10.1\n  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (1.24.3)\nRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (11.0.0)\nCollecting dill<0.3.7,>=0.3.0 (from datasets==2.10.1)\n  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (0.70.15)\nRequirement already satisfied: fsspec>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.11.1->datasets==2.10.1) (2023.12.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (3.8.5)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (0.20.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (0.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.10.1) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (2023.11.17)\nINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\nCollecting multiprocess (from datasets==2.10.1)\n  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.1) (1.16.0)\nInstalling collected packages: dill, multiprocess, datasets\n  Attempting uninstall: dill\n    Found existing installation: dill 0.3.7\n    Uninstalling dill-0.3.7:\n      Successfully uninstalled dill-0.3.7\n  Attempting uninstall: multiprocess\n    Found existing installation: multiprocess 0.70.15\n    Uninstalling multiprocess-0.70.15:\n      Successfully uninstalled multiprocess-0.70.15\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\npathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.6 which is incompatible.\npathos 0.3.1 requires multiprocess>=0.70.15, but you have multiprocess 0.70.14 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.10.1 dill-0.3.6 multiprocess-0.70.14\nCollecting fire==0.5.0\n  Downloading fire-0.5.0.tar.gz (88 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire==0.5.0) (2.3.0)\nBuilding wheels for collected packages: fire\n  Building wheel for fire (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=3a13cdef0aef6c9680f9a7074580d7c8e05703cd290be777b614365af5d94e17\n  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\nSuccessfully built fire\nInstalling collected packages: fire\nSuccessfully installed fire-0.5.0\nCollecting git+https://github.com/huggingface/peft.git\n  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-pfb3ebyk\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-pfb3ebyk\n  Resolved https://github.com/huggingface/peft.git to commit fff24008ebf6ee24fe869af45fccb77ed58294aa\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (4.36.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (4.66.1)\nCollecting accelerate>=0.21.0 (from peft==0.8.2.dev0)\n  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (0.4.1)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.8.2.dev0) (0.20.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2.dev0) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2.dev0) (2023.12.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2.dev0) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.8.2.dev0) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.8.2.dev0) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2.dev0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2.dev0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.8.2.dev0) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.8.2.dev0) (2023.8.8)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.8.2.dev0) (0.15.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.8.2.dev0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2.dev0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.8.2.dev0) (2023.11.17)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.8.2.dev0) (1.3.0)\nDownloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: peft\n  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for peft: filename=peft-0.8.2.dev0-py3-none-any.whl size=183430 sha256=9a12d08af38d1f1968addcffd983bca604630688bf41356f8051152d16d2d6aa\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0_92kac7/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\nSuccessfully built peft\nInstalling collected packages: accelerate, peft\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.18.0\n    Uninstalling accelerate-0.18.0:\n      Successfully uninstalled accelerate-0.18.0\nSuccessfully installed accelerate-0.26.1 peft-0.8.2.dev0\nCollecting git+https://github.com/huggingface/transformers.git\n  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-ww918f1w\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ww918f1w\n  Resolved https://github.com/huggingface/transformers.git to commit 7b2bd1fbbd50e57cf28013e2d0737912ecc0f2eb\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.20.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.15.0)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (0.4.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.0.dev0) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (2023.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.38.0.dev0) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.0.dev0) (2023.11.17)\nBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.38.0.dev0-py3-none-any.whl size=8451153 sha256=c7ff34587825f76731e0b898cb84064449babf0b768f3827792a6305e8e29345\n  Stored in directory: /tmp/pip-ephem-wheel-cache-gw1fqu7q/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\nSuccessfully built transformers\nInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.36.2\n    Uninstalling transformers-4.36.2:\n      Successfully uninstalled transformers-4.36.2\nSuccessfully installed transformers-4.38.0.dev0\nRequirement already satisfied: torch==2.0.0 in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0) (1.3.0)\nCollecting sentencepiece==0.1.97\n  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentencepiece\n  Attempting uninstall: sentencepiece\n    Found existing installation: sentencepiece 0.1.99\n    Uninstalling sentencepiece-0.1.99:\n      Successfully uninstalled sentencepiece-0.1.99\nSuccessfully installed sentencepiece-0.1.97\nCollecting tensorboardX==2.6\n  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.6) (1.24.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.6) (21.3)\nRequirement already satisfied: protobuf<4,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from tensorboardX==2.6) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorboardX==2.6) (3.0.9)\nInstalling collected packages: tensorboardX\n  Attempting uninstall: tensorboardX\n    Found existing installation: tensorboardX 2.6.2.2\n    Uninstalling tensorboardX-2.6.2.2:\n      Successfully uninstalled tensorboardX-2.6.2.2\nSuccessfully installed tensorboardX-2.6\nCollecting gradio==3.23.0\n  Downloading gradio-3.23.0-py3-none-any.whl (15.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting aiofiles (from gradio==3.23.0)\n  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (3.8.5)\nRequirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (5.2.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (0.101.1)\nCollecting ffmpy (from gradio==3.23.0)\n  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (2023.12.2)\nCollecting httpx (from gradio==3.23.0)\n  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (0.20.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (3.1.2)\nRequirement already satisfied: markdown-it-py>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (3.0.0)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (2.1.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (3.7.4)\nCollecting mdit-py-plugins<=0.3.3 (from gradio==3.23.0)\n  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (1.24.3)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (3.9.5)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (2.0.3)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (9.5.0)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (1.10.12)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (0.25.1)\nCollecting python-multipart (from gradio==3.23.0)\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (2.31.0)\nCollecting semantic-version (from gradio==3.23.0)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (4.5.0)\nRequirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (0.23.2)\nRequirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio==3.23.0) (12.0)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.23.0) (4.19.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.23.0) (21.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.23.0) (0.12.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->gradio==3.23.0) (3.12.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->gradio==3.23.0) (4.66.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.0.0->markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (0.1.2)\nRequirement already satisfied: linkify-it-py<3,>=1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (2.0.2)\nINFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\nCollecting mdit-py-plugins<=0.3.3 (from gradio==3.23.0)\n  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\nINFO: pip is still looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\nCollecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.23.0)\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio==3.23.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio==3.23.0) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio==3.23.0) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio==3.23.0) (1.3.1)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio==3.23.0) (0.27.0)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.23.0) (3.7.1)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.23.0) (2023.11.17)\nCollecting httpcore==1.* (from httpx->gradio==3.23.0)\n  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.23.0) (3.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio==3.23.0) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->gradio==3.23.0) (0.14.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio==3.23.0) (3.0.9)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->gradio==3.23.0) (1.26.15)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->gradio==3.23.0) (8.1.7)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0) (2023.7.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0) (0.30.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.23.0) (0.9.2)\nRequirement already satisfied: uc-micro-py in /opt/conda/lib/python3.10/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.23.0) (1.0.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->gradio==3.23.0) (1.16.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->gradio==3.23.0) (1.1.3)\nDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\nDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=31cbef3a9a8d60022f264a59ebd6bcbad4d24ec83e091e2ce944134f279ad1e4\n  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, semantic-version, python-multipart, markdown-it-py, httpcore, aiofiles, mdit-py-plugins, httpx, gradio\n  Attempting uninstall: markdown-it-py\n    Found existing installation: markdown-it-py 3.0.0\n    Uninstalling markdown-it-py-3.0.0:\n      Successfully uninstalled markdown-it-py-3.0.0\n  Attempting uninstall: mdit-py-plugins\n    Found existing installation: mdit-py-plugins 0.4.0\n    Uninstalling mdit-py-plugins-0.4.0:\n      Successfully uninstalled mdit-py-plugins-0.4.0\nSuccessfully installed aiofiles-23.2.1 ffmpy-0.3.1 gradio-3.23.0 httpcore-1.0.2 httpx-0.26.0 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 python-multipart-0.0.6 semantic-version-2.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#!pip install seaborn","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import transformers\nimport textwrap\nfrom transformers import AutoTokenizer,AutoModelForCausalLM\nimport os\nimport sys\nfrom typing import List\n\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    get_peft_model_state_dict,\n    prepare_model_for_int8_training,\n)\n\nimport fire\nimport torch\nfrom datasets import load_dataset, Dataset\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nfrom pylab import rcParams\nimport json\n\n%matplotlib inline\nsns.set(rc={'figure.figsize':(8, 6)})\nsns.set(rc={'figure.dpi':100})\nsns.set(style='white', palette='muted', font_scale=1.2)\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:17:55.399606Z","iopub.execute_input":"2024-01-31T17:17:55.399919Z","iopub.status.idle":"2024-01-31T17:18:00.330695Z","shell.execute_reply.started":"2024-01-31T17:17:55.399891Z","shell.execute_reply":"2024-01-31T17:18:00.329777Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:18:00.331786Z","iopub.execute_input":"2024-01-31T17:18:00.332338Z","iopub.status.idle":"2024-01-31T17:18:00.338319Z","shell.execute_reply.started":"2024-01-31T17:18:00.332311Z","shell.execute_reply":"2024-01-31T17:18:00.337106Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(3512, 2)"},"metadata":{}}]},{"cell_type":"code","source":"model_name='mistralai/Mistral-7B-v0.1'","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:18:00.339657Z","iopub.execute_input":"2024-01-31T17:18:00.339993Z","iopub.status.idle":"2024-01-31T17:18:00.354931Z","shell.execute_reply.started":"2024-01-31T17:18:00.339962Z","shell.execute_reply":"2024-01-31T17:18:00.354038Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model=AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map='auto', load_in_8bit=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:18:00.356056Z","iopub.execute_input":"2024-01-31T17:18:00.356354Z","iopub.status.idle":"2024-01-31T17:19:15.580560Z","shell.execute_reply.started":"2024-01-31T17:18:00.356330Z","shell.execute_reply":"2024-01-31T17:19:15.579573Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa91d6d68165423888757c1ea84879be"}},"metadata":{}},{"name":"stderr","text":"The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb908726c3414f4d8b53acc34cbaf7a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d89f09be5584e66b23cca3ed1a7f557"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"225a1e3a64f3487b84a9b47e212a3c27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4637eb0762c407ba202bbc31738760e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00421d59f1c340908258ec6657befc58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5eac69ae9d464f8fb5651b296e82f6e4"}},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:19:42.666569Z","iopub.status.idle":"2024-01-31T17:19:42.666891Z","shell.execute_reply.started":"2024-01-31T17:19:42.666734Z","shell.execute_reply":"2024-01-31T17:19:42.666749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:20:12.585678Z","iopub.execute_input":"2024-01-31T17:20:12.586065Z","iopub.status.idle":"2024-01-31T17:20:12.763928Z","shell.execute_reply.started":"2024-01-31T17:20:12.586034Z","shell.execute_reply":"2024-01-31T17:20:12.763109Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenizer.pad_token_id=(0)\ntokenizer.padding_side='left'","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:20:15.982596Z","iopub.execute_input":"2024-01-31T17:20:15.983510Z","iopub.status.idle":"2024-01-31T17:20:15.987631Z","shell.execute_reply.started":"2024-01-31T17:20:15.983476Z","shell.execute_reply":"2024-01-31T17:20:15.986673Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"prompt=\"I am suffering from mental Problem and facing these issues:\\n I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? \\n Please provide me with a solution. \\nSolution: \\n\"","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:20:19.286705Z","iopub.execute_input":"2024-01-31T17:20:19.287588Z","iopub.status.idle":"2024-01-31T17:20:19.292288Z","shell.execute_reply.started":"2024-01-31T17:20:19.287552Z","shell.execute_reply":"2024-01-31T17:20:19.290971Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"max_length=1500","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:20:22.228789Z","iopub.execute_input":"2024-01-31T17:20:22.229174Z","iopub.status.idle":"2024-01-31T17:20:22.234169Z","shell.execute_reply.started":"2024-01-31T17:20:22.229145Z","shell.execute_reply":"2024-01-31T17:20:22.233214Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"encoded_ids=tokenizer(prompt, truncation=True, return_tensors='pt', max_length=max_length, padding=True).to(model.device)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:20:25.565194Z","iopub.execute_input":"2024-01-31T17:20:25.566065Z","iopub.status.idle":"2024-01-31T17:20:25.571334Z","shell.execute_reply.started":"2024-01-31T17:20:25.566029Z","shell.execute_reply":"2024-01-31T17:20:25.570468Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"generated_ids=model.generate(**encoded_ids, max_length=max_length, num_beams=5, no_repeat_ngram_size=2, do_sample=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:20:28.265346Z","iopub.execute_input":"2024-01-31T17:20:28.266103Z","iopub.status.idle":"2024-01-31T17:21:07.934091Z","shell.execute_reply.started":"2024-01-31T17:20:28.266070Z","shell.execute_reply":"2024-01-31T17:21:07.933274Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"answer=tokenizer.decode(generated_ids[0], skip_special_tokens=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:21:14.195633Z","iopub.execute_input":"2024-01-31T17:21:14.196402Z","iopub.status.idle":"2024-01-31T17:21:14.201177Z","shell.execute_reply.started":"2024-01-31T17:21:14.196347Z","shell.execute_reply":"2024-01-31T17:21:14.200202Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(answer)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:22:00.321049Z","iopub.execute_input":"2024-01-31T17:22:00.321462Z","iopub.status.idle":"2024-01-31T17:22:00.326344Z","shell.execute_reply.started":"2024-01-31T17:22:00.321430Z","shell.execute_reply":"2024-01-31T17:22:00.325517Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"I am suffering from mental Problem and facing these issues:\n I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here. I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it. How can I change my feeling of being worthless to everyone? \n Please provide me with a solution. \nSolution: \nYou need to get help from a mental health professional. There are many resources available to you. You can call the National Suicide Prevention Lifeline at 1-800-273-TALK (8255) or visit their website at https://suicidepreventionlifeline.org/. They can provide you with support and resources to help you through this difficult time. It's important to remember that you are not alone and that there is help available.\n","output_type":"stream"}]},{"cell_type":"code","source":"data=Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:21:27.401722Z","iopub.execute_input":"2024-01-31T17:21:27.402615Z","iopub.status.idle":"2024-01-31T17:21:27.462168Z","shell.execute_reply.started":"2024-01-31T17:21:27.402571Z","shell.execute_reply":"2024-01-31T17:21:27.461173Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:21:29.931292Z","iopub.execute_input":"2024-01-31T17:21:29.932469Z","iopub.status.idle":"2024-01-31T17:21:29.938332Z","shell.execute_reply.started":"2024-01-31T17:21:29.932432Z","shell.execute_reply":"2024-01-31T17:21:29.937391Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Context', 'Response'],\n    num_rows: 3512\n})"},"metadata":{}}]},{"cell_type":"code","source":"max_length=1500","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:21:33.880148Z","iopub.execute_input":"2024-01-31T17:21:33.880539Z","iopub.status.idle":"2024-01-31T17:21:33.884754Z","shell.execute_reply.started":"2024-01-31T17:21:33.880507Z","shell.execute_reply":"2024-01-31T17:21:33.883877Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"data=data.train_test_split(test_size=200, seed=42, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:21:36.244789Z","iopub.execute_input":"2024-01-31T17:21:36.245594Z","iopub.status.idle":"2024-01-31T17:21:36.269981Z","shell.execute_reply.started":"2024-01-31T17:21:36.245561Z","shell.execute_reply":"2024-01-31T17:21:36.269215Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"data['validation']=data['test']\ndel data['test']","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:21:39.400040Z","iopub.execute_input":"2024-01-31T17:21:39.400456Z","iopub.status.idle":"2024-01-31T17:21:39.404838Z","shell.execute_reply.started":"2024-01-31T17:21:39.400421Z","shell.execute_reply":"2024-01-31T17:21:39.403883Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:21:41.751225Z","iopub.execute_input":"2024-01-31T17:21:41.751923Z","iopub.status.idle":"2024-01-31T17:21:41.757575Z","shell.execute_reply.started":"2024-01-31T17:21:41.751891Z","shell.execute_reply":"2024-01-31T17:21:41.756744Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Context', 'Response'],\n        num_rows: 3312\n    })\n    validation: Dataset({\n        features: ['Context', 'Response'],\n        num_rows: 200\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def generate_prompt(data_point):\n    prompt=f\"I am suffering from mental Problem and facing these issues:\\n{data_point['Context']}\\n Please provide me with a solution. \\nSolution:\\n{data_point['Response']}\"\n    return prompt","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:23:09.965420Z","iopub.execute_input":"2024-01-31T17:23:09.966168Z","iopub.status.idle":"2024-01-31T17:23:09.970557Z","shell.execute_reply.started":"2024-01-31T17:23:09.966134Z","shell.execute_reply":"2024-01-31T17:23:09.969678Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def tokenize_prompt(prompt, add_eos_token=True):\n    result=tokenizer(prompt, truncation=True, max_length=max_length, padding=False, return_tensors=None)\n    if(result['input_ids'][-1]!=tokenizer.eos_token_id and len(result['input_ids'])<max_length and add_eos_token):\n        result['input_ids'].append(tokenizer.eos_token_id)\n        result['attention_mask'].append(1)\n    result['labels']=result['input_ids'].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:23:13.237675Z","iopub.execute_input":"2024-01-31T17:23:13.238047Z","iopub.status.idle":"2024-01-31T17:23:13.244478Z","shell.execute_reply.started":"2024-01-31T17:23:13.238016Z","shell.execute_reply":"2024-01-31T17:23:13.243501Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def generate_and_tokenize_prompt(data_point):\n    prompt=generate_prompt(data_point)\n    tokens=tokenize_prompt(prompt)\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:23:16.541132Z","iopub.execute_input":"2024-01-31T17:23:16.542147Z","iopub.status.idle":"2024-01-31T17:23:16.546689Z","shell.execute_reply.started":"2024-01-31T17:23:16.542107Z","shell.execute_reply":"2024-01-31T17:23:16.545563Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"train_data = (\n    data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n)\nval_data = (\n    data[\"validation\"].shuffle().map(generate_and_tokenize_prompt)\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:23:19.945056Z","iopub.execute_input":"2024-01-31T17:23:19.945466Z","iopub.status.idle":"2024-01-31T17:23:24.935542Z","shell.execute_reply.started":"2024-01-31T17:23:19.945434Z","shell.execute_reply":"2024-01-31T17:23:24.934565Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3312 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"LORA_R = 8\nLORA_ALPHA = 16\nLORA_DROPOUT= 0.05\nLORA_TARGET_MODULES = [\n    \"q_proj\",\n    \"v_proj\",\n]\n\nBATCH_SIZE = 8\nMICRO_BATCH_SIZE = 4\nGRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE\nLEARNING_RATE = 3e-4\nTRAIN_STEPS = 1000\nOUTPUT_DIR = \"experiments\"","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:23:32.004798Z","iopub.execute_input":"2024-01-31T17:23:32.005542Z","iopub.status.idle":"2024-01-31T17:23:32.010444Z","shell.execute_reply.started":"2024-01-31T17:23:32.005509Z","shell.execute_reply":"2024-01-31T17:23:32.009543Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model=prepare_model_for_int8_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:23:34.812782Z","iopub.execute_input":"2024-01-31T17:23:34.813617Z","iopub.status.idle":"2024-01-31T17:23:34.830604Z","shell.execute_reply.started":"2024-01-31T17:23:34.813571Z","shell.execute_reply":"2024-01-31T17:23:34.829771Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:143: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"config=LoraConfig(r=LORA_R, lora_alpha=LORA_ALPHA, lora_dropout=LORA_DROPOUT, bias='none', task_type='CAUSAL_LM')\nmodel=get_peft_model(model, config)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:23:52.559060Z","iopub.execute_input":"2024-01-31T17:23:52.559865Z","iopub.status.idle":"2024-01-31T17:23:52.680998Z","shell.execute_reply.started":"2024-01-31T17:23:52.559829Z","shell.execute_reply":"2024-01-31T17:23:52.680057Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:23:55.835830Z","iopub.execute_input":"2024-01-31T17:23:55.836202Z","iopub.status.idle":"2024-01-31T17:23:55.849955Z","shell.execute_reply.started":"2024-01-31T17:23:55.836175Z","shell.execute_reply":"2024-01-31T17:23:55.849052Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralAttention(\n              (q_proj): lora.Linear8bitLt(\n                (base_layer): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n              (v_proj): lora.Linear8bitLt(\n                (base_layer): Linear8bitLt(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n              (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)\n              (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm()\n            (post_attention_layernorm): MistralRMSNorm()\n          )\n        )\n        (norm): MistralRMSNorm()\n      )\n      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:24:01.014569Z","iopub.execute_input":"2024-01-31T17:24:01.014944Z","iopub.status.idle":"2024-01-31T17:24:02.108977Z","shell.execute_reply.started":"2024-01-31T17:24:01.014916Z","shell.execute_reply":"2024-01-31T17:24:02.107688Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Wed Jan 31 17:24:01 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   60C    P0              28W /  70W |   4437MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   65C    P0              32W /  70W |   8927MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"model.print_trainable_parameters()","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:24:11.598998Z","iopub.execute_input":"2024-01-31T17:24:11.599399Z","iopub.status.idle":"2024-01-31T17:24:11.611562Z","shell.execute_reply.started":"2024-01-31T17:24:11.599371Z","shell.execute_reply":"2024-01-31T17:24:11.610676Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n","output_type":"stream"}]},{"cell_type":"code","source":"training_arguments=transformers.TrainingArguments(\n    per_device_train_batch_size=MICRO_BATCH_SIZE,\n    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n    warmup_steps=0,\n    max_steps=TRAIN_STEPS,\n    learning_rate=LEARNING_RATE,\n    fp16=True,\n    logging_steps=5,\n    optim='adamw_torch',\n    evaluation_strategy='steps',\n    eval_steps=10,\n    output_dir=OUTPUT_DIR,\n    report_to='tensorboard'\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:24:21.127933Z","iopub.execute_input":"2024-01-31T17:24:21.128388Z","iopub.status.idle":"2024-01-31T17:24:21.153997Z","shell.execute_reply.started":"2024-01-31T17:24:21.128335Z","shell.execute_reply":"2024-01-31T17:24:21.153171Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"data_collator = transformers.DataCollatorForSeq2Seq(\n    tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:24:24.899572Z","iopub.execute_input":"2024-01-31T17:24:24.900043Z","iopub.status.idle":"2024-01-31T17:24:25.143044Z","shell.execute_reply.started":"2024-01-31T17:24:24.900002Z","shell.execute_reply":"2024-01-31T17:24:25.142280Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"trainer=transformers.Trainer(model=model, train_dataset=train_data, eval_dataset=val_data, args=training_arguments, data_collator=data_collator)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:24:30.768235Z","iopub.execute_input":"2024-01-31T17:24:30.769181Z","iopub.status.idle":"2024-01-31T17:24:30.818247Z","shell.execute_reply.started":"2024-01-31T17:24:30.769143Z","shell.execute_reply":"2024-01-31T17:24:30.817464Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-31T17:24:38.724881Z","iopub.execute_input":"2024-01-31T17:24:38.725643Z","iopub.status.idle":"2024-01-31T17:24:52.929456Z","shell.execute_reply.started":"2024-01-31T17:24:38.725612Z","shell.execute_reply":"2024-01-31T17:24:52.927432Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1561\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1893\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1890\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1892\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1893\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1896\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1899\u001b[0m ):\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1901\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2813\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2813\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2816\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2836\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2835\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2836\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2837\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2838\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:687\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/utils/operations.py:675\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/amp/autocast_mode.py:14\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:1083\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mpeft_type \u001b[38;5;241m==\u001b[39m PeftType\u001b[38;5;241m.\u001b[39mPOLY:\n\u001b[1;32m   1082\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_ids\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:161\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1173\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1170\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;66;03m# Shift so that tokens < n predict n\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m     shift_logits \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m     shift_labels \u001b[38;5;241m=\u001b[39m labels[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;66;03m# Flatten the tokens\u001b[39;00m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 230.00 MiB (GPU 1; 14.75 GiB total capacity; 13.53 GiB already allocated; 165.06 MiB free; 14.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 230.00 MiB (GPU 1; 14.75 GiB total capacity; 13.53 GiB already allocated; 165.06 MiB free; 14.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"model.save_pretrained(OUTPUT_DIR, safe_serialization=False)","metadata":{},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub('Garsa3112/FinetunedForALMA13BLoRA', token='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')","metadata":{},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b65d1d6faacf4180acdb2aadf2ef25e2","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/26.2M [00:00<?, ?B/s]"]},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/Garsa3112/FinetunedForALMA13BLoRA/commit/2fe756e8767c9a7f2dfa25830956a199e97c0681', commit_message='Upload model', commit_description='', oid='2fe756e8767c9a7f2dfa25830956a199e97c0681', pr_url=None, pr_revision=None, pr_num=None)"]},"metadata":{}}]},{"cell_type":"code","source":"prompt='Translate from Chinese to English:\\nChinese:1997年,在辩论一项要求总统确认俄罗斯导弹已经不再瞄准的修正案时,柯特·韦尔登(英语:Curt Weldon)代表向国会记录(英语:Congressional Record)介绍了与俄罗斯将军的60分钟采访记录,其中指出俄罗斯的洲际弹道导弹可以在几分钟之内重新指向美国目标。 \\nEnglish:'","metadata":{},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"tokenized_ids=tokenizer(prompt, return_tensors='pt')","metadata":{},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{},"execution_count":72,"outputs":[{"name":"stdout","output_type":"stream","text":"Wed Jan  3 00:42:15 2024       \n\n+---------------------------------------------------------------------------------------+\n\n| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n\n|-----------------------------------------+----------------------+----------------------+\n\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n\n|                                         |                      |               MIG M. |\n\n|=========================================+======================+======================|\n\n|   0  NVIDIA RTX A6000               On  | 00000000:3D:00.0 Off |                  Off |\n\n| 30%   31C    P8              15W / 300W |  22776MiB / 49140MiB |      0%      Default |\n\n|                                         |                      |                  N/A |\n\n+-----------------------------------------+----------------------+----------------------+\n\n                                                                                         \n\n+---------------------------------------------------------------------------------------+\n\n| Processes:                                                                            |\n\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n\n|        ID   ID                                                             Usage      |\n\n|=======================================================================================|\n\n+---------------------------------------------------------------------------------------+\n"}]},{"cell_type":"code","source":"tokenized_ids=tokenized_ids.to('cuda')","metadata":{},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"generated_ids=model.generate(**tokenized_ids, num_beams=5, early_stopping=True, no_repeat_ngram_size=2)","metadata":{},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"generated_ids","metadata":{},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":["tensor([[    1,  4103,  9632,   515, 10013,   304,  4223, 29901,    13,  1451,\n","          8233, 29901, 29896, 29929, 29929, 29955, 30470, 29892, 30505,   235,\n","           193,   172,   235,   177,   189, 30287, 31888, 30698, 31376,   233,\n","           131,   190, 31675, 31835, 31439,   231,   194,   135,   234,   192,\n","           154, 31824, 31943,   232,   191,   188, 31290, 31412, 30413, 31733,\n","           234,   161,   135,   232,   138,   137, 30210, 31273, 30724,   233,\n","           164,   139, 30594, 29892,   233,   162,   178, 31141, 30064,   236,\n","           162,   169, 31814, 31451, 29898, 31144, 31505, 29901, 29907,  4227,\n","           399,  2495,   265, 29897, 30690, 30746, 31331, 30356, 30437, 31410,\n","         31283, 29898, 31144, 31505, 29901, 29907,   549, 29878, 15750, 14164,\n","         29897, 31633,   234,   190,   144, 30743, 31267,   231,   194,   135,\n","           234,   192,   154, 31824, 30998, 31867, 30210, 29953, 29900, 30748,\n","           236,   149,   162,   236,   138,   138,   235,   177,   194, 31410,\n","         31283, 29892, 31149, 30275, 31084, 30544,   231,   194,   135,   234,\n","           192,   154, 31824, 30210, 31952,   236,   156,   136,   232,   191,\n","           188, 30397, 31943,   232,   191,   188, 30682, 30651, 30505,   232,\n","           138,   163, 30748,   236,   149,   162, 30577, 30728, 30908, 30374,\n","         31084, 31331, 30630, 30356, 30895, 31062, 30267, 29871,    13, 24636,\n","         29901,   797, 29871, 29896, 29900, 29953,   386, 11559,  1919,  2645,\n","           263, 27836,   373,   385,   626,   355,   358,   304,  1996,   278,\n","          7178,   304, 18145,  5485,   393, 10637,  3052,  5475,   892,   694,\n","          5520,  3646,   287,  1919, 25141, 10458,  1145,  1919,   263, 21097,\n","          1919,  9129,   304,   278,   378, 11476,   284,  2407,   263,  1301,\n","           924,   310,   263,  1354, 29312, 29899,  1195,  1082, 15593,   411,\n","           263, 10637,  2498,  1919,   297,   607,   540,  8703,   393,   278,\n","         10637,  1006,  1285, 25270,  8287,  4695,  3052,   488,  1033,   367,\n","          6684,   287,   304,  3082, 22525,  2629,  6233,   869,     2]],\n","       device='cuda:0')"]},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.decode(generated_ids[0], skip_special_tokens=True)","metadata":{},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":["'Translate from Chinese to English:\\nChinese:1997年,在辩论一项要求总统确认俄罗斯导弹已经不再瞄准的修正案时,柯特·韦尔登(英语:Curt Weldon)代表向国会记录(英语:Congressional Record)介绍了与俄罗斯将军的60分钟采访记录,其中指出俄罗斯的洲际弹道导弹可以在几分钟之内重新指向美国目标。 \\nEnglish:In 106th Congress , during a debate on an amendment to require the President to acknowledge that Russian missiles were no longer targeted , Curt Welden , a representative , introduced to the congressional record a transcript of a sixty-minute interview with a Russian general , in which he stated that the Russian intercontinental ballistic missile could be redirected to American targets within minutes .'"]},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}